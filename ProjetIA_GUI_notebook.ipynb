{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GUI of The Model ‚ù§"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_We have used tkinter for the GUI of model, a simple one to test our model_üòä"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![dd](https://lithub.com/wp-content/uploads/2019/07/writing.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### importation des Librairies ‚úî"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importer torch\n",
    "import skimage \n",
    "from skimage import morphology\n",
    "import torch\n",
    "import skimage\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from skimage import transform as tf\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction & Preprocessing ‚úî "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#####  IMAGE TRANSFORMATIONS  #####\n",
    "\n",
    "def to_binary(img) :\n",
    "  img = np.array(img, dtype=float)\n",
    "  for i in range(0, 28):\n",
    "    for k in range(0, 28):\n",
    "      if img[i][k] != 0 :\n",
    "        img[i][k] = 1\n",
    "  return img\n",
    "  \n",
    "def to_thin(img):\n",
    "  img_bin = to_binary(img)\n",
    "  img_skl = skimage.morphology.skeletonize(img_bin)\n",
    "  thin= skimage.morphology.thin(img_skl , max_iter=3)\n",
    "  return thin\n",
    "\n",
    "def crop(img):\n",
    "    img = img[~np.all(img == 0, axis=1)]\n",
    "    img = np.transpose(img)\n",
    "    img = img[~np.all(img== 0, axis=1)]\n",
    "    img = np.transpose(img)\n",
    "    img = tf.resize(img, (28, 28), order=0)\n",
    "    return img\n",
    "\n",
    "def split(img):\n",
    "\tblocks = []\n",
    "\t[row, col] = img.shape\n",
    "\tfor i in range (0, row, 7):\n",
    "\t\tfor j in range(0, col, 7):\n",
    "\t\t\tblocks.append(img[i:i+7, j:j+7])\n",
    "\treturn blocks\n",
    "\n",
    "#####  BLOCK HELPERS  #####\n",
    "\n",
    "def black_pix(block):\n",
    "\tS =0\n",
    "\tfor i in range(0,7):\n",
    "\t\tfor j in range(0,7):\n",
    "\t\t\tif block[i][j] != 0:\n",
    "\t\t\t\tS += 1\n",
    "\treturn S / (block.shape[0] * block.shape[1])\n",
    "\n",
    "def get_coordinates(block):\n",
    "\tX=[]\n",
    "\tY=[]\n",
    "\t\n",
    "\tfor i in range(0, 7):\n",
    "\t\tfor j in range(0, 7):\n",
    "\t\t\tif block[i][j] != 0:\n",
    "\t\t\t\tY.append(i)\n",
    "\t\t\t\tX.append(j)\n",
    "\treturn X,Y\n",
    "\n",
    "#####  FEATURE EXTRACTORS  #####\n",
    "\n",
    "def get_features(block) : \n",
    "\tone = black_pix(block)\n",
    "\ttwo = 0\n",
    "\tthree = 0\n",
    "\t\n",
    "\tX, Y = get_coordinates(block)\n",
    "\t\t\n",
    "\tif len(X) > 0 :\n",
    "\t\tX = np.array(X).reshape((-1, 1))\n",
    "\t\tY = np.array(Y)\n",
    "\t\treg = LinearRegression()\n",
    "\t\treg.fit(X,Y)\n",
    "\t\ta=reg.coef_\n",
    "\t\t\n",
    "\t\ttwo   = 2 * a / (1 + a ** 2)\n",
    "\t\tthree = (1 - a ** 2) / (1 + a ** 2) \n",
    "\n",
    "\treturn float(one), float(two), float(three)\n",
    "\n",
    "def show_slopes(img):\n",
    "\timg = to_thin(img)\n",
    "\timg = crop(img)\n",
    "\tblocks = split(img)\n",
    "\n",
    "\tfigure = plt.figure(figsize=(10, 14))\n",
    "\tfor index in range(1, 17):\n",
    "\t\t  plt.subplot(4, 4, index)\n",
    "\t\t  blck = blocks[index-1]\n",
    "\t\t  X, Y = get_coordinates(blck)\n",
    "\t\t  a = -1\n",
    "\t\t  b = 0\n",
    "\t\t  if len(X) > 0 :\n",
    "\t\t    X = np.array(X).reshape((-1, 1))\n",
    "\t\t    Y = np.array(Y)\n",
    "\t\t    reg = LinearRegression()\n",
    "\t\t    reg.fit(X,Y)\n",
    "\t\t    a = reg.coef_\n",
    "\t\t    b = reg.intercept_\n",
    "\t\t  plt.title(\"{:.2f}\".format(float(a)))\n",
    "\t\t  plt.imshow(blck, cmap='gray')\n",
    "\t\t  if len(X) > 0 :\n",
    "\t\t    plt.plot([0, 6], [b, a*7+b])\n",
    "\tplt.show()\n",
    "\n",
    "def preprocess(img):\n",
    "\timg = to_thin(img)\n",
    "\timg = crop(img)\n",
    "\tblocks = split(img)\n",
    "\t\n",
    "\tins = []\n",
    "\t\n",
    "\tfor blck in blocks:\n",
    "\t\tone, two, three = get_features(blck)\n",
    "\t\tins.append(one)\n",
    "\t\tins.append(two)\n",
    "\t\tins.append(three)\n",
    "\t\t\n",
    "\treturn ins\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notre NN ‚úî"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importer le module nn\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net (nn.Module):\n",
    "    def __init__ (self):\n",
    "        \n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(48, 200)\n",
    "        nn.BatchNorm1d(200)\n",
    "        nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(200, 100)\n",
    "        nn.BatchNorm1d(100)\n",
    "        nn.Dropout(0.5)\n",
    "        self.fc4= nn.Linear(100, 20)\n",
    "        nn.BatchNorm1d(20)\n",
    "        nn.Dropout(0.5)\n",
    "        self.fc5= nn.Linear(20, 20)\n",
    "        nn.BatchNorm1d(20)\n",
    "        nn.Dropout(0.5)\n",
    "        self.fc3= nn.Linear(20, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.selu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.selu(self.fc4(x))\n",
    "        x = F.relu(self.fc5(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we go with Tkinter ‚ù§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully\n",
      "successfully\n",
      "34 99 638 503\n",
      "34 99 638 503\n",
      "34 99 638 503\n",
      "34 99 638 503\n"
     ]
    }
   ],
   "source": [
    "from tkinter import *\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import ImageGrab, Image, ImageDraw\n",
    "import torch\n",
    "\n",
    "\n",
    "model= Net()\n",
    "model.load_state_dict(torch.load(\"model_final_cas6.pth\"))\n",
    "model.eval()\n",
    "print(\"successfully\")\n",
    "\n",
    "image_folder = \"C:/Users/OMAIMA/Desktop/mnist\"\n",
    "print(\"successfully\")\n",
    "\n",
    "# canvas\n",
    "root = Tk()\n",
    "root.resizable(0, 0)\n",
    "root.title(\"I can guess your handwritten digits üñå \")\n",
    "\n",
    "width  = 600\n",
    "height = 400\n",
    "bg     = (255, 255, 255)\n",
    "\n",
    "lastx, lasty = None, None\n",
    "image_number = 0\n",
    "image        = Image.new(\"RGB\", (width, height), bg)\n",
    "draw         = ImageDraw.Draw(image)\n",
    "\n",
    "canvas = Canvas(root, width=width, height=height, bg=\"white\")\n",
    "canvas.grid(row=0, column=0, pady=2, sticky=NSEW, columnspan=2)\n",
    "\n",
    "def activate_event(event):\n",
    "    global lastx, lasty\n",
    "    canvas.bind('<B1-Motion>', draw_lines)\n",
    "    lastx, lasty = event.x, event.y\n",
    "def draw_lines(event):\n",
    "    global lastx, lasty\n",
    "    x, y = event.x, event.y\n",
    "    canvas.create_line((lastx, lasty, x, y), width=8, fill='black', capstyle=ROUND, smooth=TRUE, splinesteps=12)\n",
    "    draw.line([lastx, lasty, x, y], fill='black', width=8)\n",
    "    lastx, lasty = x, y\n",
    "canvas.bind('<Button-1>', activate_event)\n",
    "\n",
    "\n",
    "def clear_widget():\n",
    "    global canvas, image, draw\n",
    "    canvas.delete('all')\n",
    "    image = Image.new(\"RGB\", (width, height), bg)\n",
    "    draw = ImageDraw.Draw(image)\n",
    "button_clear = Button(text='Clear Output',width=15, height=3, command=clear_widget)\n",
    "button_clear.grid(row=2, column=1, pady=1, padx=1)\n",
    "\n",
    "def Recognize_Digit():\n",
    "\tglobal image_number\n",
    "\tglobal canvas\n",
    "\tfilename = f'img_{image_number}.png'\n",
    "    \n",
    "\tx = root.winfo_rootx() + canvas.winfo_x()\n",
    "\ty = root.winfo_rooty() + canvas.winfo_y()\n",
    "\tx1 = x + canvas.winfo_width()\n",
    "\ty1 = y + canvas.winfo_height()\n",
    "\tprint(x, y, x1, y1)\n",
    "    \n",
    "\timage.save(image_folder + filename)\n",
    "\timg = cv2.imread(image_folder + filename, cv2.IMREAD_COLOR)\n",
    "\tgray = cv2.cvtColor(img.copy(), cv2.COLOR_BGR2GRAY)\n",
    "\tret, th = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "\n",
    "\tcontours = cv2.findContours(th, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0]\n",
    "    \n",
    "\tfor cnt in contours:\n",
    "\t\tx, y, w, h = cv2.boundingRect(cnt)\n",
    "\t\t# make a rectangle box around each curve\n",
    "\t\tcv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 0), 1)\n",
    "\n",
    "\t\t# Cropping out the digit from the image corresponding to the current contours in the for loop\n",
    "\t\tdigit = th[y:y + h, x:x + w]\n",
    "\n",
    "\t\t# Resizing that digit to (18, 18)\n",
    "\t\tresized_digit = cv2.resize(digit, (18, 18))\n",
    "\n",
    "\t\t# Padding the digit with 5 pixels of black color (zeros) in each side to finally produce the image of (28, 28)\n",
    "\t\tpadded_digit = np.pad(resized_digit, ((5, 5), (5, 5)), \"constant\", constant_values=0)\n",
    "\n",
    "\t\tdigit = padded_digit.reshape(28, 28)\n",
    "\t\tins = preprocess(digit)\n",
    "\t\tins= torch.tensor(ins).reshape(1,48)\n",
    "\t\tpred = model(ins.float())\n",
    "\t\tfinal_pred = torch.argmax(pred)\n",
    "\n",
    "\t\tdata = str(final_pred)\n",
    "\n",
    "\t\tfont = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\t\tfontScale = 0.5\n",
    "\t\tcolor = (255, 0, 0)\n",
    "\t\tthickness = 1\n",
    "\t\tcv2.putText(img, data, (x, y - 5), font, fontScale, color, thickness)\n",
    "\n",
    "\tcv2.imshow('Pr√©dictions', img)\n",
    "\tcv2.waitKey(10000) \n",
    "\n",
    "btn_rec = Button(text='Recognize Digits',width=15, height=3, command=Recognize_Digit)\n",
    "btn_rec.grid(row=2, column=0, pady=1, padx=1)\n",
    "\n",
    "\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Made with ‚ù§‚ù§‚ù§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
